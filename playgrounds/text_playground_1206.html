<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Text-to-Text Playground</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap"
        rel="stylesheet">

    <link rel="stylesheet" href="./styles/text_playground.css">
    <link rel="icon" type="image/x-icon" href="../assets/b-profile-pic.png">

    <!-- Model output Text formatting -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>


    <!-- Prism CSS -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-coy.min.css" rel="stylesheet" />


    <!-- Prism Core -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>

    <!-- Language Components -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-javascript.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-html.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-css.min.js"></script>


</head>

<body>

    <h2>Text-to-Text Generator</h2>
    <div class="window">
        <div class="sidebar section-style">
            <label for="apiKey">Text API Key</label>
            <input type="password" id="apiKey" placeholder="sk_qwertyasdfgh" />
            <label for="model">Model name</label>
            <!-- https://huggingface.co/api/partners/fal-ai/models -->
            <!-- https://huggingface.co/api/models?inference_provider=fal-ai&pipeline_tag=text-to-image -->
            <select id="model">
                <!-- <option value="deepseek/deepseek-r1-distill-llama-70b:free">DeepSeek: R1 Distill Llama 70B (free)</option> -->
                <!-- <option value="google/gemini-2.0-flash-thinking-exp:free">Google: Gemini 2.0 Flash Thinking Experimental 01-21 (free)</option> -->
                <!-- <option value="google/gemini-2.5-pro-exp-03-25:free">Google: Gemini 2.5 Pro Experimental (free)</option> -->
                <!-- <option value="google/gemma-3-12b-it:free">Google: Gemma 3 12B (free)</option> -->
                <!-- <option value="google/gemma-3-1b-it:free">Google: Gemma 3 1B (free)</option> -->
                <!-- <option value="google/gemma-3-27b-it:free">Google: Gemma 3 27B (free)</option> -->
                <!-- <option value="google/gemma-3-4b-it:free">Google: Gemma 3 4B (free)</option> -->
                <!-- <option value="mistralai/mistral-small-24b-instruct-2501:free">Mistral: Mistral Small 3 (free)</option> -->
                <!-- <option value="mistralai/mistral-small-3.1-24b-instruct:free">Mistral: Mistral Small 3.1 24B (free)</option> -->
                <!-- <option value="sophosympatheia/rogue-rose-103b-v0.2:free">Rogue Rose 103B v0.2 (free)</option> -->
                <!-- <option value="google/gemma-3-4b-it">Google: Gemma 3 4B</option> -->
                <!-- <option value="deepseek/deepseek-r1-distill-llama-8b">DeepSeek: R1 Distill Llama 8B</option> -->
                <option value="google/gemma-3-12b-it">Google: Gemma 3 12B</option>
                <!-- <option value="mistral/ministral-8b">Mistral: Ministral 8B</option> -->
                <!-- <option value="mistralai/mistral-small-24b-instruct-2501">Mistral: Mistral Small 3</option> -->
                <!-- <option value="scb10x/llama3.1-typhoon2-8b-instruct">Typhoon2 8B Instruct</option> -->
                <!-- <option value="google/gemma-3-27b-it">Google: Gemma 3 27B</option> -->
                <!-- <option value="tokyotech-llm/llama-3.1-swallow-8b-instruct-v0.3">Swallow: Llama 3.1 Swallow 8B Instruct V0.3</option> -->
                <option value="meta-llama/llama-guard-3-8b">Llama Guard 3 8B</option>
                <!-- <option value="google/gemini-2.0-flash-lite-001">Google: Gemini 2.0 Flash Lite</option> -->
                <!-- <option value="mistralai/mistral-small-3.1-24b-instruct">Mistral: Mistral Small 3.1 24B</option> -->
                <option value="google/gemini-2.0-flash-001">Google: Gemini 2.0 Flash</option>
                <option value="openai/gpt-4o-mini-search-preview">OpenAI: GPT-4o-mini Search Preview</option>
                <!-- <option value="mistralai/mistral-saba">Mistral: Saba</option> -->
                <!-- <option value="deepseek/deepseek-r1-distill-llama-70b">DeepSeek: R1 Distill Llama 70B</option> -->
                <!-- <option value="mistralai/codestral-2501">Mistral: Codestral 2501</option> -->
                <!-- <option value="scb10x/llama3.1-typhoon2-70b-instruct">Typhoon2 70B Instruct</option> -->
                <!-- <option value="latitudegames/wayfarer-large-70b-llama-3.3">LatitudeGames: Wayfarer Large 70B Llama 3.3 </option> -->
                <!-- <option value="tokyotech-llm/llama-3.1-swallow-70b-instruct-v0.3">Swallow: Llama 3.1 Swallow 70B Instruct V0.3</option> -->
            </select>
            <h3>Settings (optional)</h3>
            <label for="max_tokens">max_tokens</label>
            <input type="number" id="max_tokens" min="1" max="1000" step="100" placeholder="1">
            <p class="info">integer | Optional | Maximum number of tokens (range: [1, context_length)).</p>

            <label for="temperature">temperature</label>
            <input type="number" id="temperature" min="0" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Sampling temperature (range: [0, 2]).</p>

            <label for="top_p">top_p</label>
            <input type="number" id="top_p" min="0.1" max="1" step="0.1" placeholder="1">
            <p class="info">double | Optional | Top-p sampling value (range: (0, 1]).</p>

            <!-- <label for="top_k">top_k</label>
            <input type="number" id="top_k" rows="1" placeholder="1">
            <p class="info">integer | Optional | Top-k sampling value (range: [1, Infinity)).</p> -->

            <!-- <label for="frequency_penalty">frequency_penalty</label>
            <input type="number" id="frequency_penalty" min="-2" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Frequency penalty (range: [-2, 2]).</p> -->

            <!-- <label for="presence_penalty">presence_penalty</label>
            <input type="number" id="presence_penalty" min="-2" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Presence penalty (range: [-2, 2]).</p> -->

            <label for="repetition_penalty">repetition_penalty</label>
            <input type="number" id="repetition_penalty" min="0.1" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Repetition penalty (range: (0, 2]).</p>

            <!-- <label for="logit_bias">logit_bias</label>
            <textarea id="logit_bias" rows="1" placeholder="1"></textarea>
            <p class="info">map from strings to doubles | Optional | Mapping of token IDs to bias values.</p> -->

            <!-- <label for="top_logprobs">top_logprobs</label>
            <textarea id="top_logprobs" rows="1" placeholder="1"></textarea>
            <p class="info">integer | Optional | Number of top log probabilities to return.</p> -->

            <!-- <label for="min_p">min_p</label>
            <textarea id="min_p" rows="1" placeholder="1"></textarea>
            <p class="info">double | Optional | Minimum probability threshold (range: [0, 1]).</p>

            <label for="top_a">top_a</label>
            <textarea id="top_a" rows="1" placeholder="1"></textarea>
            <p class="info">double | Optional | Alternate top sampling parameter (range: [0, 1]).</p> -->



            <div class="toggle_container">
                <p>Show/hide the model info</p>
                <img id="toggle_icon_model_info" class="toggle_img" src="../assets/icons/toggle_off.svg"
                    alt="Toggle view model info" onclick="toggle_model_info()">
                <div id="result_model_info" class="toggle_disp">
                    <pre class="json_format">{}</pre>
                </div>
            </div>


        </div>



        <div class="convo section-style">
            <div id="chat-window">
                <div id="result"></div>
                <div id="loading_div"></div>
                <!-- <div id="result_info"></div> -->
            </div>

            <label for="prompt">Prompt:</label>
            <div id="button_container">
                <textarea id="prompt" rows="4" placeholder="What colour is the sky?"></textarea>


                <div>
                    <button onclick="generateCompletion()">Generate</button>
                    <button onclick="giveExample()">Give me an example</button>
                    <button onclick="saveChat()">Save</button>
                </div>
            </div>
            <div class="toggle_container">
                <p>Show/hide the input json</p>
                <img id="toggle_icon_input" class="toggle_img" src="../assets/icons/toggle_off.svg"
                    alt="Toggle view input json" onclick="toggle_input_json()">
                <div id="input" class="toggle_disp">
                    <pre class="json_format">{}</pre>
                </div>
            </div>


            <!-- template toggle functions -->
            <!-- toggle icon -->
            <!-- <img id="toggleIcon" class="toggle_img" src="../assets/icons/toggle_off.svg" alt="Toggle"
                onclick="toggleElement()">-->

            <!-- Hidden Element -->
            <!--<div id="toggle_element" class = "toggle_disp">
                Hello! You toggled me.
            </div> -->

        </div>
    </div>
    <div id="result_logging"></div>
    <div id="file_saved_ts">1716290942000</div>
    <div id="last_output_ts">1716290942000</div>


    <script>

        //get model list...... optionss



        // Wait for the DOM to load
        // document.addEventListener("DOMContentLoaded", () => {
        // const dropdown = document.getElementById("fruits");

        // Fetch the JSON list
        // fetch('https://bethatcurtin.github.io/files/openrouter_models.json')
        // fetch('../files/openrouter_models.json')



        document.addEventListener("DOMContentLoaded", () => {
            const dropdown = document.getElementById("models");

            // Fetch your JSON file (e.g., models.json)
            fetch('openrouter_models.json') // <-- replace with your actual file path
                .then(response => response.json())
                .then(data => {
                    const models = data.models_list; // Extract the list

                    models.forEach(modelId => {
                        const option = document.createElement("option");
                        option.value = modelId;
                        option.textContent = modelId;
                        dropdown.appendChild(option);
                    });
                })
                .catch(error => {
                    console.error("Error loading models:", error);
                });
        });
        async function return_model_info() {
            const raw_data = await fetch('https://bethatcurtin.github.io/files/openrouter_models.json')
            data = await raw_data.json()

            console.log('Loaded JSON:', data);
            // You can now use data.name, data.version, etc.
            return data
        }

        // Any time these fields are updated, the 'input join' function is called, which updates the input json.
        // document.getElementById('model').addEventListener('change', fetchModelInfo);
        document.getElementById('model').addEventListener('change', input_join);
        document.getElementById('prompt').addEventListener('change', input_join);
        document.getElementById('max_tokens').addEventListener('change', input_join);
        document.getElementById('temperature').addEventListener('change', input_join);
        // document.getElementById('seed').addEventListener('change', input_join);
        document.getElementById('top_p').addEventListener('change', input_join);
        // document.getElementById('top_k').addEventListener('change', input_join);
        // document.getElementById('frequency_penalty').addEventListener('change', input_join);
        // document.getElementById('presence_penalty').addEventListener('change', input_join);
        document.getElementById('repetition_penalty').addEventListener('change', input_join);

        //When the user is in the prompt field and presses a key, the logKey function is triggered (and generateCompletion() is called if the key is Enter key)
        document.getElementById("prompt").addEventListener("keydown", logKey);

        //Set up the toggle visibility defaults
        let isVisible = false;
        let input_json_visible = false;
        let model_info_visible = false;


        //not sure what this is for
        const inputDiv = document.getElementById('input');

        //this function binds the <Enter> key to the 'generate' function
        function logKey(e) {
            if (e.code == 'Enter') {
                e.preventDefault(); // don't enter a return character
                generateCompletion() // run the generate() function
            }
        }


        // template toggle function
        function toggleElement() {
            const element = document.getElementById("toggle_element");
            const icon = document.getElementById("toggleIcon");

            //Toggle visibility
            isVisible = !isVisible;
            //Show or hide the element
            element.style.display = isVisible ? "block" : "none";
            //Change the appearance of the 'toggle' icon itself
            icon.src = isVisible ? "../assets/icons/toggle_on.svg" : "../assets/icons/toggle_off.svg";
        }


        // This function controls the toggle visibility for the json input section
        function toggle_input_json() {
            const element = document.getElementById("input");
            const icon = document.getElementById("toggle_icon_input");


            //Toggle visibility
            input_json_visible = !input_json_visible;
            //Show or hide the element
            element.style.display = input_json_visible ? "block" : "none";
            //Change the appearance of the 'toggle' icon itself
            icon.src = input_json_visible ? "../assets/icons/toggle_on.svg" : "../assets/icons/toggle_off.svg";

        }

        // This function controls the toggle visibility for the model info section
        function toggle_model_info() {
            const element = document.getElementById("result_model_info");
            const icon = document.getElementById("toggle_icon_model_info");
            //Toggle visibility
            model_info_visible = !model_info_visible;
            //Show or hide the element
            element.style.display = model_info_visible ? "block" : "none";
            //Change the appearance of the 'toggle' icon itself
            icon.src = model_info_visible ? "../assets/icons/toggle_on.svg" : "../assets/icons/toggle_off.svg";

            //Refresh the info section
            fetchModelInfo();
        }

        // This function populates the 'prompt' field with a random example prompt
        async function giveExample() {
            document.getElementById('prompt');

            // Retrieve from the example text prompts list
            const prompt_examples_list = await fetch('https://bethatcurtin.github.io/files/text_prompt_examples.json')
            data = await prompt_examples_list.json()
            console.log('Loaded JSON:', data);

            const prompt_list = data.text_prompt_examples;
            console.log('Loaded list:', prompt_list);
            console.log('size:', prompt_list.length);

            //Retrieve a random item from this list
            const randomNumber = Math.floor(Math.random() * prompt_list.length)
            const randomItem = prompt_list[randomNumber];
            console.log('radnom: ', randomItem)
            // Update the Prompt field with the selected item
            document.getElementById("prompt").value = randomItem;
            // Run the input_join function to refresh the input data
            input_join()
        }


        function log_ts(id) {
            //The 'id' passed in is the id of the div to be updated (either file_saved_ts or last_output_ts)
            //Time that the log file was last saved: file_saved_ts
            //Time that the last output was generated: last_output_ts
            const ts_log = document.getElementById(id);
            const ts = Date.now();
            ts_log.innerHTML = ts;
        }


        // This function retreives the logged data and downloads it as a .txt file. The .txt file's name contains a user ID and the Unix TS.
        function saveChat() {
            const chatContent = document.getElementById('result_logging').innerText;
            const blob = new Blob([chatContent], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const apiKey = document.getElementById("apiKey").value.trim();
            const ts = Date.now();

            // Get the last 5 characters of the apiKey for user identifier
            let key = apiKey;
            const id = key.slice(-5);

            // Shorten the TS to seconds instead of milliseconds
            ts_secs = Math.floor(ts / 1000);

            // Create & download the file
            const a = document.createElement('a');
            a.href = url;
            a.download = `chat_id-${id}_ts-${ts_secs}.txt`;
            a.click();

            // Update the event TS logs
            log_ts('file_saved_ts')

            // Clean up
            URL.revokeObjectURL(url);

        }


        // This function retrieves the model information to display in the info block.
        async function fetchModelInfo() {
            const model = document.getElementById('model').value;
            // const hfId = models_aliases[model]?.hfId;

            const resultDiv = document.getElementById('result_model_info');

            if (!model) {
                resultDiv.innerHTML = '';
                return;
            }

            resultDiv.innerHTML = 'Loading...';
            console.log(model)
            const info = await return_model_info(model)


            resultDiv.innerHTML = `<div><h3>Model Information</h3>
<pre><strong>Model Name:</strong> ${info.name}<br>
<strong>Model Info:</strong> ${info.description}<br>
<strong>Inputs:</strong> ${info.inputs}<br>
<strong>Price (US):</strong> $${info.price_completion} per ouput token, $${info.price_prompt} per ouput token</pre></div>`;

        }



        async function return_model_info(model_name) {





            const raw_data = await fetch('https://bethatcurtin.github.io/files/openrouter_models.json')
            data = await raw_data.json()

            console.log('Loaded JSON:', data);
            // You can now use data.name, data.version, etc.
            const model = data[model_name];
            console.log('Model: ', model)
            if (model) {
                return model;
            } else {
                throw new Error(`Model "${model_name}" not found.`);
            }










        }







        //This function is triggered when any field is changed.  The field values are used to construct the input json which is sent to the model and displayed in the 'input json' element. 
        function input_join() {
            const prompt = document.getElementById("prompt").value.trim();
            const model = document.getElementById("model").value.trim();
            const max_tokens = document.getElementById("max_tokens").value.trim();
            const temperature = document.getElementById("temperature").value.trim();

            // const seed = document.getElementById("seed").value.trim()

            const top_p = document.getElementById("top_p").value.trim();
            // const top_k = document.getElementById("top_k").value.trim();
            // const frequency_penalty = document.getElementById("frequency_penalty").value.trim();
            // const presence_penalty = document.getElementById("presence_penalty").value.trim();
            const repetition_penalty = document.getElementById("repetition_penalty").value.trim();


            const input = {
                model: model,
                prompt: prompt
            }

            if (max_tokens) {
                input.reasoning = {};
                input.reasoning.max_tokens = Number(max_tokens);
            }
            if (temperature) {
                input.temperature = Number(temperature);
            }
            // if (seed) {
            //     input.seed = Number(seed);
            // }
            if (top_p) {
                input.top_p = Number(top_p);
            }
            // if (top_k) {
            //     input.top_k = Number(top_k);
            // }
            // if (frequency_penalty) {
            //     input.frequency_penalty = Number(frequency_penalty);
            // }
            // if (presence_penalty) {
            //     input.presence_penalty = Number(presence_penalty);
            // }
            if (repetition_penalty) {
                input.repetition_penalty = Number(repetition_penalty);
            }

            console.log(input)

            // Update the input json
            inputDiv.innerHTML = `<pre class="json_format">${JSON.stringify(input, null, 4)}</pre>`;
            return input
        }


        //This function appends raw logs (i.e. not formatted for html display) to the log data
        //This keeps a record of the chat data and timestamps in the download file format
        function file_format_append(mode, content) {
            //The "mode" is 'Input' or 'Output' or 'Error'
            //The "content" is some string that is passed to the function - usually prompt, output or error data.

            const utcDate = new Date(Date.now());
            const timestamp = utcDate.toTimeString()
            console.log(timestamp);

            const logs = document.getElementById("result_logging");

            //Create the next element to add
            const add_log = document.createElement('div')
            add_log.innerHTML = `### ${timestamp} ###
${mode}:
${content}


`
            // Append the new element
            logs.appendChild(add_log);

            return
        }



        //This function calls the OpenRouter Completions API with the input json and returns the result. 
        async function generateCompletion() {
            const apiKey = document.getElementById("apiKey").value.trim();
            const model = document.getElementById("model").value;
            const prompt = document.getElementById("prompt").value;
            const resultDiv = document.getElementById("result");
            const resultInfo = document.getElementById("result_info");
            const loadingDiv = document.getElementById("loading_div");

            // Refresh the input_data
            const input_send = input_join();
            console.log(input_send)



            // Create new result element
            const newResult = document.createElement('div');
            const chatWindow = document.getElementById('chat-window');
            //if a value is missing, don't continue
            if (!apiKey || !prompt || !model) {
                newResult.innerHTML = `<p style="margin-top:5px;">All fields are required.</p>`
                resultDiv.appendChild(newResult);
                loadingDiv.innerHTML = "";
                chatWindow.scrollTop = chatWindow.scrollHeight;
                return;
            }
            // Create the new Input element and show the input in the chat Window
            const newInput = document.createElement('div');
            newInput.innerHTML = `<div class="msg"><h3 class="input">User Input</h3><p>${input_send.prompt}</p></div>`;
            resultDiv.appendChild(newInput);
            // Append the input to the log data
            file_format_append('Input', `${input_send.prompt}`)

            // Show the loader and Scroll to the bottom of the Chat window
            loadingDiv.innerHTML = `<p><br>Generating response...</p><img src="../assets/icons/spinner-ring.svg">`;
            chatWindow.scrollTop = chatWindow.scrollHeight;



            // Call the OpenRouter API
            try {

                const response = await fetch(`https://openrouter.ai/api/v1/completions`, {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${apiKey}`,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify(input_send)

                });
                console.log(response);

                //If there was an error, log it
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.error || "Error generating response");

                }

                const result = await response.json();
                console.log(result);
                //Stop showing the loader 
                loadingDiv.innerHTML = "";


                //Retrieve the content of the completion
                const text_response = result.choices[0].text;

                //Format the text using markdown
                const formattedText = marked.parse(text_response);
                console.log(formattedText)

                //Retrieve some metadata for logging
                const finish_reason = result.choices[0].finish_reason;
                const response_id = result.id;



                //Construct the html for displaying the text in the Chat window
                newResult.innerHTML = `<div class="msg"><h3 class="output">${model}:</h3><p>${formattedText}<br><br><span style="color: red";>debug<br>id: ${response_id}<br>finish_reason:${finish_reason}</span></p></div>`;
                //Append and show the new result
                resultDiv.appendChild(newResult);
                //Append the log info to the logging data
                file_format_append('Output', `${model}
${formattedText}

id: ${response_id}
finish_reason: ${finish_reason}`)
                //Log the timestamp of the output
                log_ts('last_output_ts')

                //Scroll down to the bottom of the window to show the output
                const chatWindow = document.getElementById('chat-window');
                chatWindow.scrollTop = chatWindow.scrollHeight;

                return result; //I think move this below cause there are lots of repeated lines
            } catch (error) {

                // Construct the error message
                newResult.innerHTML = `<p style="color: red;">Error: ${error.message}<br>Prompt: "${prompt}"</p>`;
                //Dispaly the error message in the chat window
                resultDiv.appendChild(newResult);

                // Construct the log data and call the function to append to the log data
                file_format_append('Error', `Error: ${error.message}, Prompt: "${prompt}"`)
                //Update the output ts
                log_ts('last_output_ts')

                const chatWindow = document.getElementById('chat-window');
                chatWindow.scrollTop = chatWindow.scrollHeight;
                console.error(error);

            }

            //move some stuff here and the return statement...
        }


        // Remind the user to download their logs before leaving/refreshing
        window.addEventListener('beforeunload', function (e) {
            const last_saved = document.getElementById('file_saved_ts').innerHTML;
            const last_output = document.getElementById('last_output_ts').innerHTML;


            //This will remind the user to save their log file if they have generated an output more recently than if they saved the file (i.e. time of last output > time of last logfile download)
            console.log(last_output > last_saved)
            if (last_output > last_saved) {
                // Show confirmation dialog - this doesnt seem to show anywhere tho
                const confirmationMessage = "Make sure you download your chat records before you leave! Save them to your USB file.";
                e.returnValue = confirmationMessage; // Required for Chrome
                return confirmationMessage;          // Required for Firefox
            }


        });
    </script>

</body>

</html>
