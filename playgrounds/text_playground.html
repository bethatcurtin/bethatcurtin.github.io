<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Text-to-Text Playground</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap"
        rel="stylesheet">

    <link rel="stylesheet" href="./styles/text_playground.css">
    <link rel="icon" type="image/x-icon" href="../assets/b-profile-pic.png">

    <!-- Model output Text formatting -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>


    <!-- Prism CSS -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-coy.min.css" rel="stylesheet" />


    <!-- Prism Core -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>

    <!-- Language Components -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-javascript.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-html.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-css.min.js"></script>


</head>

<body>

    <h2>Text-to-Text Generator</h2>
    <div class="window">
        <div class="sidebar section-style">
            <label for="apiKey">Text API Key</label>
            <input type="password" id="apiKey" placeholder="sk_qwertyasdfgh" />

            <label for="model">Model name</label>
            <!-- https://huggingface.co/api/partners/fal-ai/models -->
            <!-- https://huggingface.co/api/models?inference_provider=fal-ai&pipeline_tag=text-to-image -->
            <select id="model">
                <!--                 <option value="deepseek/deepseek-r1-distill-llama-70b:free">DeepSeek: R1 Distill Llama 70B (free)
                </option>
                <option value="google/gemini-2.0-flash-thinking-exp:free">Google: Gemini 2.0 Flash Thinking Experimental
                    01-21 (free)</option> -->
                <!--                 <option value="google/gemini-2.5-pro-exp-03-25:free">Google: Gemini 2.5 Pro Experimental (free)</option>
                <option value="google/gemma-3-12b-it:free">Google: Gemma 3 12B (free)</option>
                <option value="google/gemma-3-1b-it:free">Google: Gemma 3 1B (free)</option>
                <option value="google/gemma-3-27b-it:free">Google: Gemma 3 27B (free)</option> -->
                <option value="google/gemma-3-4b-it:free">Google: Gemma 3 4B (free)</option>
                <!--   <option value="mistralai/mistral-small-24b-instruct-2501:free">Mistral: Mistral Small 3 (free)</option>
                <option value="mistralai/mistral-small-3.1-24b-instruct:free">Mistral: Mistral Small 3.1 24B (free)
                </option>
                <option value="sophosympatheia/rogue-rose-103b-v0.2:free">Rogue Rose 103B v0.2 (free)</option> -->
                <!--                 <option value="google/gemma-3-4b-it">Google: Gemma 3 4B</option> -->
                <!--                 <option value="deepseek/deepseek-r1-distill-llama-8b">DeepSeek: R1 Distill Llama 8B</option> -->
                <option value="google/gemma-3-12b-it">Google: Gemma 3 12B</option>
                <!--                 <option value="mistral/ministral-8b">Mistral: Ministral 8B</option>
                <option value="mistralai/mistral-small-24b-instruct-2501">Mistral: Mistral Small 3</option>
                <option value="scb10x/llama3.1-typhoon2-8b-instruct">Typhoon2 8B Instruct</option> -->
                <!--                 <option value="google/gemma-3-27b-it">Google: Gemma 3 27B</option> -->
                <!--                 <option value="tokyotech-llm/llama-3.1-swallow-8b-instruct-v0.3">Swallow: Llama 3.1 Swallow 8B Instruct
                    V0.3</option> -->
                <option value="meta-llama/llama-guard-3-8b">Llama Guard 3 8B</option>
                <option value="google/gemini-2.0-flash-lite-001">Google: Gemini 2.0 Flash Lite</option>
                <!--                 <option value="mistralai/mistral-small-3.1-24b-instruct">Mistral: Mistral Small 3.1 24B</option> -->
                <option value="google/gemini-2.0-flash-001">Google: Gemini 2.0 Flash</option>
                <option value="openai/gpt-4o-mini-search-preview">OpenAI: GPT-4o-mini Search Preview</option>
                <!--                 <option value="mistralai/mistral-saba">Mistral: Saba</option> -->
                <!--                 <option value="deepseek/deepseek-r1-distill-llama-70b">DeepSeek: R1 Distill Llama 70B</option> -->
                <!--                 <option value="mistralai/codestral-2501">Mistral: Codestral 2501</option> -->
                <!--                 <option value="scb10x/llama3.1-typhoon2-70b-instruct">Typhoon2 70B Instruct</option> -->
                <!--                 <option value="latitudegames/wayfarer-large-70b-llama-3.3">LatitudeGames: Wayfarer Large 70B Llama 3.3 -->
                <!--                 </option> -->
                <option value="tokyotech-llm/llama-3.1-swallow-70b-instruct-v0.3">Swallow: Llama 3.1 Swallow 70B
                    Instruct V0.3</option>


            </select>
            <h3>Settings (optional)</h3>

            <label for="max_tokens">max_tokens</label>
            <input type="number" id="max_tokens" min="1" max="1000" step="100" placeholder="1">
            <p class="info">integer | Optional | Maximum number of tokens (range: [1, context_length)).</p>

            <label for="temperature">temperature</label>
            <input type="number" id="temperature" min="0" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Sampling temperature (range: [0, 2]).</p>

            <!-- <label for="seed">seed</label>
            <input type="number" id="seed" rows="1" placeholder="1">
            <p class="info">integer | Optional | Seed for deterministic outputs.</p> -->

            <label for="top_p">top_p</label>
            <input type="number" id="top_p" min="0.1" max="1" step="0.1" placeholder="1">
            <p class="info">double | Optional | Top-p sampling value (range: (0, 1]).</p>

            <!-- <label for="top_k">top_k</label>
            <input type="number" id="top_k" rows="1" placeholder="1">
            <p class="info">integer | Optional | Top-k sampling value (range: [1, Infinity)).</p> -->

            <!-- <label for="frequency_penalty">frequency_penalty</label>
            <input type="number" id="frequency_penalty" min="-2" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Frequency penalty (range: [-2, 2]).</p> -->

            <!-- <label for="presence_penalty">presence_penalty</label>
            <input type="number" id="presence_penalty" min="-2" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Presence penalty (range: [-2, 2]).</p> -->

            <label for="repetition_penalty">repetition_penalty</label>
            <input type="number" id="repetition_penalty" min="0.1" max="2" step="0.1" placeholder="1">
            <p class="info">double | Optional | Repetition penalty (range: (0, 2]).</p>

            <!-- <label for="logit_bias">logit_bias</label>
            <textarea id="logit_bias" rows="1" placeholder="1"></textarea>
            <p class="info">map from strings to doubles | Optional | Mapping of token IDs to bias values.</p> -->

            <!-- <label for="top_logprobs">top_logprobs</label>
            <textarea id="top_logprobs" rows="1" placeholder="1"></textarea>
            <p class="info">integer | Optional | Number of top log probabilities to return.</p> -->

            <!-- <label for="min_p">min_p</label>
            <textarea id="min_p" rows="1" placeholder="1"></textarea>
            <p class="info">double | Optional | Minimum probability threshold (range: [0, 1]).</p>

            <label for="top_a">top_a</label>
            <textarea id="top_a" rows="1" placeholder="1"></textarea>
            <p class="info">double | Optional | Alternate top sampling parameter (range: [0, 1]).</p> -->



            <div class="toggle_container">
                <p>Show/hide the model info</p>
                <img id="toggle_icon_model_info" class="toggle_img" src="../assets/icons/toggle_off.svg"
                    alt="Toggle view model info" onclick="toggle_model_info()">
                <div id="result_model_info" class="toggle_disp">
                    <pre class="json_format">{}</pre>
                </div>
            </div>


        </div>



        <div class="convo section-style">
            <div id="chat-window">
                <div id="result"></div>
                <div id="loading_div"></div>
                <!-- <div id="result_info"></div> -->
            </div>

            <label for="prompt">Prompt:</label>
            <div id="button_container">
                <textarea id="prompt" rows="4" placeholder="What colour is the sky?"></textarea>


                <div>
                    <button onclick="generateCompletion()">Generate</button>
                    <button onclick="giveExample()">Give me an example</button>
                    <button onclick="saveChat()">Save</button>
                </div>
            </div>
            <div class="toggle_container">
                <p>Show/hide the input json</p>
                <img id="toggle_icon_input" class="toggle_img" src="../assets/icons/toggle_off.svg"
                    alt="Toggle view input json" onclick="toggle_input_json()">
                <div id="input" class="toggle_disp">
                    <pre class="json_format">{}</pre>
                </div>
            </div>


            <!-- template toggle functions -->
            <!-- toggle icon -->
            <!-- <img id="toggleIcon" class="toggle_img" src="../assets/icons/toggle_off.svg" alt="Toggle"
                onclick="toggleElement()">-->

            <!-- Hidden Element -->
            <!--<div id="toggle_element" class = "toggle_disp">
                Hello! You toggled me.
            </div> -->

        </div>
    </div>
    <div id="result_logging"></div>
    <div id="file_saved_ts">1716290942000</div>
    <div id="last_output_ts">1716290942000</div>


    <script>

        // document.getElementById('model').addEventListener('change', fetchModelInfo);
        document.getElementById('model').addEventListener('change', input_join);
        document.getElementById('prompt').addEventListener('change', input_join);
        document.getElementById('max_tokens').addEventListener('change', input_join);
        document.getElementById('temperature').addEventListener('change', input_join);
        // document.getElementById('seed').addEventListener('change', input_join);
        document.getElementById('top_p').addEventListener('change', input_join);
        // document.getElementById('top_k').addEventListener('change', input_join);
        // document.getElementById('frequency_penalty').addEventListener('change', input_join);
        // document.getElementById('presence_penalty').addEventListener('change', input_join);
        document.getElementById('repetition_penalty').addEventListener('change', input_join);


        document.getElementById("prompt").addEventListener("keydown", logKey);


        let isVisible = false;
        let input_json_visible = false;
        let model_info_visible = false;
        const inputDiv = document.getElementById('input');

        function logKey(e) {
            if (e.code == 'Enter') {
                generateCompletion()
            }
        }


        // template toggle func
        function toggleElement() {
            const element = document.getElementById("toggle_element");
            const icon = document.getElementById("toggleIcon");

            isVisible = !isVisible;
            element.style.display = isVisible ? "block" : "none";
            icon.src = isVisible ? "../assets/icons/toggle_on.svg" : "../assets/icons/toggle_off.svg";
        }


        // toggle the json input visibility
        function toggle_input_json() {
            const element = document.getElementById("input");
            const icon = document.getElementById("toggle_icon_input");



            input_json_visible = !input_json_visible;
            element.style.display = input_json_visible ? "block" : "none";
            icon.src = input_json_visible ? "../assets/icons/toggle_on.svg" : "../assets/icons/toggle_off.svg";

        }

        // toggle the model info visibility
        function toggle_model_info() {
            const element = document.getElementById("result_model_info");
            const icon = document.getElementById("toggle_icon_model_info");

            model_info_visible = !model_info_visible;
            element.style.display = model_info_visible ? "block" : "none";
            icon.src = model_info_visible ? "../assets/icons/toggle_on.svg" : "../assets/icons/toggle_off.svg";
            fetchModelInfo();
        }

        // gives the user a random example prompt
        async function giveExample() {
            document.getElementById('prompt');
            const prompt_examples_list = await fetch('https://bethatcurtin.github.io/files/text_prompt_examples.json')
            data = await prompt_examples_list.json()

            console.log('Loaded JSON:', data);

            const prompt_list = data.text_prompt_examples;

            console.log('Loaded list:', prompt_list);
            console.log('size:', prompt_list.length);

            const randomNumber = Math.floor(Math.random() * prompt_list.length)
            const randomItem = prompt_list[randomNumber];
            console.log('radnom: ', randomItem)
            document.getElementById("prompt").value = randomItem;
            input_join()
        }


        function log_ts(id) {
            //id = div id
            //file saved = file_saved_ts
            //last output = last_output_ts
            const ts_log = document.getElementById(id);
            const ts = Date.now();
            ts_log.innerHTML = ts;


        }

        function saveChat() {
            const chatContent = document.getElementById('result_logging').innerText;
            // const file_saved_log = document.getElementById('file_saved_ts');
            const blob = new Blob([chatContent], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const apiKey = document.getElementById("apiKey").value.trim();

            const ts = Date.now();

            let key = apiKey;
            const id = key.slice(-5);
            ts_secs = Math.floor(ts / 1000);
            const a = document.createElement('a');
            a.href = url;
            a.download = `chat_id${id}_ts${ts_secs}.txt`;
            a.click();

            log_ts('file_saved_ts')
            // file_saved_log.innerHTML=ts;



            // Clean up
            URL.revokeObjectURL(url);

        }



        async function fetchModelInfo() {
            const model = document.getElementById('model').value;
            const hfId = models_aliases[model]?.hfId;

            const resultDiv = document.getElementById('result_model_info');

            if (!model) {
                resultDiv.innerHTML = '';
                return;
            }

            resultDiv.innerHTML = 'Loading...';

            try {
                const response = await fetch(`https://huggingface.co/api/models?id=${hfId}`);
                console.log(model)
                console.log(hfId)
                const data = await response.json();

                if (!Array.isArray(data) || data.length === 0) {
                    resultDiv.innerHTML = 'No model info found.';
                    return;
                }

                const modelInfo = data[0];
                resultDiv.innerHTML = `<h3>Model Information</h3>
  <div class="field"><strong>Model Name:</strong> ${hfId}</div>
  <div class="field"><strong>Model ID:</strong> ${modelInfo.id}</div>
  <div class="field"><strong>Created At:</strong> ${new Date(modelInfo.createdAt).toLocaleString()}</div>
  <div class="field"><strong>Downloads:</strong> ${modelInfo.downloads.toLocaleString()}</div>
  <div class="field"><strong>Likes:</strong> ${modelInfo.likes.toLocaleString()}</div>
  <div class="field"><strong>Trending Score:</strong> ${modelInfo.trendingScore}</div>
  <div class="field"><strong>Tags:</strong> ${modelInfo.tags.join(', ')}</div>
  <div class="field"><strong>Library:</strong> ${modelInfo.library_name}</div>
  <div class="field"><strong>Pipeline:</strong> ${modelInfo.pipeline_tag}</div>
`;
            } catch (error) {
                console.error(error);
                resultDiv.innerHTML = 'Error fetching model info.';
            }
        }




        function input_join() {

            const prompt = document.getElementById("prompt").value.trim();
            const model = document.getElementById("model").value.trim();
            const max_tokens = document.getElementById("max_tokens").value.trim();
            const temperature = document.getElementById("temperature").value.trim();

            // const seed = document.getElementById("seed").value.trim()

            const top_p = document.getElementById("top_p").value.trim();
            // const top_k = document.getElementById("top_k").value.trim();
            // const frequency_penalty = document.getElementById("frequency_penalty").value.trim();
            // const presence_penalty = document.getElementById("presence_penalty").value.trim();
            const repetition_penalty = document.getElementById("repetition_penalty").value.trim();


            const input = {
                model: model,
                prompt: prompt
            }

            if (max_tokens) {
                input.reasoning = {};
                input.reasoning.max_tokens = Number(max_tokens);
            }
            if (temperature) {
                input.temperature = Number(temperature);
            }
            // if (seed) {
            //     input.seed = Number(seed);
            // }
            if (top_p) {
                input.top_p = Number(top_p);
            }
            // if (top_k) {
            //     input.top_k = Number(top_k);
            // }
            // if (frequency_penalty) {
            //     input.frequency_penalty = Number(frequency_penalty);
            // }
            // if (presence_penalty) {
            //     input.presence_penalty = Number(presence_penalty);
            // }
            if (repetition_penalty) {
                input.repetition_penalty = Number(repetition_penalty);
            }

            console.log(input)


            inputDiv.innerHTML = `<pre class="json_format">${JSON.stringify(input, null, 4)}</pre>`;
            return input
        }

        function file_format_append(mode, content) {
            //this keeps a record of the chat in the download file format
            //mode is 'input' or 'output' or 'error'

            const utcDate = new Date(Date.now());
            const timestamp = utcDate.toTimeString()
            console.log(timestamp);


            const logs = document.getElementById("result_logging");
            const add_log = document.createElement('div')
            add_log.innerHTML = `### ${timestamp} ###
${mode}:
${content}


`
            logs.appendChild(add_log);

            return
        }


        async function generateCompletion() {
            const apiKey = document.getElementById("apiKey").value.trim();


            const model = document.getElementById("model").value;
            const prompt = document.getElementById("prompt").value;




            const resultDiv = document.getElementById("result");
            const resultInfo = document.getElementById("result_info");
            const loadingDiv = document.getElementById("loading_div");

            const input_send = input_join();
            console.log(input_send)

            const newInput = document.createElement('div');


            newInput.innerHTML = `<div class="msg"><h3 class="input">User Input</h3><p>${input_send.prompt}</p></div>`;
            resultDiv.appendChild(newInput);
            file_format_append('Input', `${input_send.prompt}`)
            const chatWindow = document.getElementById('chat-window');
            chatWindow.scrollTop = chatWindow.scrollHeight;



            loadingDiv.innerHTML = `<p><br>Generating response...</p><img src="../assets/icons/spinner-ring.svg">`;

            if (!apiKey || !prompt || !model) {
                resultDiv.innerHTML = "All fields are required.";
                loadingDiv.innerHTML = "";

                return;
            }


            try {

                const response = await fetch(`https://openrouter.ai/api/v1/completions`, {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${apiKey}`,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify(input_send)

                });
                console.log(response);

                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.error || "Error generating response");

                }

                const result = await response.json();
                console.log(result);
                loadingDiv.innerHTML = "";



                const text_response = result.choices[0].text;
      

                const formattedText = marked.parse(text_response);
                console.log(formattedText)
                const finish_reason = result.choices[0].finish_reason;
                const response_id = result.id;



                const newResult = document.createElement('div');
                newResult.innerHTML = `<div class="msg"><h3 class="output">${model}:</h3><p>${formattedText}<br><br><span style="color: red";>debug<br>id: ${response_id}<br>finish_reason:${finish_reason}</span></p></div>`;
                // const newResult = document.createElement('div');
                // newResult.innerHTML = formattedText;
                resultDiv.appendChild(newResult);
                file_format_append('Output', `${model}
${formattedText}

id: ${response_id}
finish_reason: ${finish_reason}`)
                log_ts('last_output_ts')

                const chatWindow = document.getElementById('chat-window');
                chatWindow.scrollTop = chatWindow.scrollHeight;





                return result;
            } catch (error) {
                const newResult = document.createElement('div');
                // Construct the error message
                newResult.innerHTML = `<p style="color: red;">Error: ${error.message}<br>Prompt: "${prompt}"</p>`;
                resultDiv.appendChild(newResult);

                // Construct the logfile's data and call the function to append to the log data
                file_format_append('Error', `Error: ${error.message}, Prompt: "${prompt}"`)
                log_ts('last_output_ts')

                const chatWindow = document.getElementById('chat-window');
                chatWindow.scrollTop = chatWindow.scrollHeight;
                console.error(error);

            }
        }


        // Remind the user to download their logs before leaving/refreshing
        window.addEventListener('beforeunload', function (e) {
            const last_saved = document.getElementById('file_saved_ts').innerHTML;
            const last_output = document.getElementById('last_output_ts').innerHTML;
            console.log("got ts")
            // const ts = Date.now();


            //10 mins??
            console.log(last_output > last_saved)
            if (last_output > last_saved) {
                // Show confirmation dialog
                const confirmationMessage = "Make sure you download your chat records before you leave! Save them to your USB file.";
                e.returnValue = confirmationMessage; // Required for Chrome
                return confirmationMessage;          // Required for Firefox
            }

        




        });
    </script>

</body>

</html>
