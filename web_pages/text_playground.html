<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Text-to-Text Playground</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="../styles/text_playground.css">
    <link rel="icon" type="image/x-icon" href="../assets/b-profile-pic.png">
</head>

<body>

    <h2>Text-to-Text Completions</h2>
    <div class="window">
        <div class="sidebar section-style">
            <label for="apiKey">openrouter api key</label>
            <input type="password" id="apiKey" placeholder="sk_qwertyasdfgh" />

            <label for="model">model</label>
            <!-- https://huggingface.co/api/partners/fal-ai/models -->
            <!-- https://huggingface.co/api/models?inference_provider=fal-ai&pipeline_tag=text-to-image -->
            <select id="model">
<!--                 <option value="deepseek/deepseek-r1-distill-llama-70b:free">DeepSeek: R1 Distill Llama 70B (free)
                </option>
                <option value="google/gemini-2.0-flash-thinking-exp:free">Google: Gemini 2.0 Flash Thinking Experimental
                    01-21 (free)</option> -->
<!--                 <option value="google/gemini-2.5-pro-exp-03-25:free">Google: Gemini 2.5 Pro Experimental (free)</option>
                <option value="google/gemma-3-12b-it:free">Google: Gemma 3 12B (free)</option>
                <option value="google/gemma-3-1b-it:free">Google: Gemma 3 1B (free)</option>
                <option value="google/gemma-3-27b-it:free">Google: Gemma 3 27B (free)</option> -->
                <option value="google/gemma-3-4b-it:free">Google: Gemma 3 4B (free)</option>
             <!--   <option value="mistralai/mistral-small-24b-instruct-2501:free">Mistral: Mistral Small 3 (free)</option>
                <option value="mistralai/mistral-small-3.1-24b-instruct:free">Mistral: Mistral Small 3.1 24B (free)
                </option>
                <option value="sophosympatheia/rogue-rose-103b-v0.2:free">Rogue Rose 103B v0.2 (free)</option> -->
<!--                 <option value="google/gemma-3-4b-it">Google: Gemma 3 4B</option> -->
<!--                 <option value="deepseek/deepseek-r1-distill-llama-8b">DeepSeek: R1 Distill Llama 8B</option> -->
                <option value="google/gemma-3-12b-it">Google: Gemma 3 12B</option>
<!--                 <option value="mistral/ministral-8b">Mistral: Ministral 8B</option>
                <option value="mistralai/mistral-small-24b-instruct-2501">Mistral: Mistral Small 3</option>
                <option value="scb10x/llama3.1-typhoon2-8b-instruct">Typhoon2 8B Instruct</option> -->
<!--                 <option value="google/gemma-3-27b-it">Google: Gemma 3 27B</option> -->
<!--                 <option value="tokyotech-llm/llama-3.1-swallow-8b-instruct-v0.3">Swallow: Llama 3.1 Swallow 8B Instruct
                    V0.3</option> -->
                <option value="meta-llama/llama-guard-3-8b">Llama Guard 3 8B</option>
                <option value="google/gemini-2.0-flash-lite-001">Google: Gemini 2.0 Flash Lite</option>
<!--                 <option value="mistralai/mistral-small-3.1-24b-instruct">Mistral: Mistral Small 3.1 24B</option> -->
                <option value="google/gemini-2.0-flash-001">Google: Gemini 2.0 Flash</option>
                <option value="openai/gpt-4o-mini-search-preview">OpenAI: GPT-4o-mini Search Preview</option>
<!--                 <option value="mistralai/mistral-saba">Mistral: Saba</option> -->
<!--                 <option value="deepseek/deepseek-r1-distill-llama-70b">DeepSeek: R1 Distill Llama 70B</option> -->
<!--                 <option value="mistralai/codestral-2501">Mistral: Codestral 2501</option> -->
<!--                 <option value="scb10x/llama3.1-typhoon2-70b-instruct">Typhoon2 70B Instruct</option> -->
<!--                 <option value="latitudegames/wayfarer-large-70b-llama-3.3">LatitudeGames: Wayfarer Large 70B Llama 3.3 -->
<!--                 </option> -->
                <option value="tokyotech-llm/llama-3.1-swallow-70b-instruct-v0.3">Swallow: Llama 3.1 Swallow 70B
                    Instruct V0.3</option>


            </select>
            <label for="max_tokens">max_tokens</label>
            <input type="number" id="max_tokens" rows="1" placeholder="1">
            <p class="info">integer | Optional | Maximum number of tokens (range: [1, context_length)).</p>

            <label for="temperature">temperature</label>
            <input type="number" id="temperature" rows="1" placeholder="1">
            <p class="info">double | Optional | Sampling temperature (range: [0, 2]).</p>

            <label for="seed">seed</label>
            <input type="number" id="seed" rows="1" placeholder="1">
            <p class="info">integer | Optional | Seed for deterministic outputs.</p>

            <label for="top_p">top_p</label>
            <input type="number" id="top_p" rows="1" placeholder="1">
            <p class="info">double | Optional | Top-p sampling value (range: (0, 1]).</p>

            <label for="top_k">top_k</label>
            <input type="number" id="top_k" rows="1" placeholder="1">
            <p class="info">integer | Optional | Top-k sampling value (range: [1, Infinity)).</p>

            <label for="frequency_penalty">frequency_penalty</label>
            <input type="number" id="frequency_penalty" rows="1" placeholder="1">
            <p class="info">double | Optional | Frequency penalty (range: [-2, 2]).</p>

            <label for="presence_penalty">presence_penalty</label>
            <input type="number" id="presence_penalty" rows="1" placeholder="1">
            <p class="info">double | Optional | Presence penalty (range: [-2, 2]).</p>

            <label for="repetition_penalty">repetition_penalty</label>
            <input type="number" id="repetition_penalty" rows="1" placeholder="1">
            <p class="info">double | Optional | Repetition penalty (range: (0, 2]).</p>

            <!-- <label for="logit_bias">logit_bias</label>
            <textarea id="logit_bias" rows="1" placeholder="1"></textarea>
            <p class="info">map from strings to doubles | Optional | Mapping of token IDs to bias values.</p> -->

            <!-- <label for="top_logprobs">top_logprobs</label>
            <textarea id="top_logprobs" rows="1" placeholder="1"></textarea>
            <p class="info">integer | Optional | Number of top log probabilities to return.</p> -->

            <!-- <label for="min_p">min_p</label>
            <textarea id="min_p" rows="1" placeholder="1"></textarea>
            <p class="info">double | Optional | Minimum probability threshold (range: [0, 1]).</p>

            <label for="top_a">top_a</label>
            <textarea id="top_a" rows="1" placeholder="1"></textarea>
            <p class="info">double | Optional | Alternate top sampling parameter (range: [0, 1]).</p> -->

            <!-- <div id="result_model_info"></div> -->

        </div>



        <div class="convo section-style">
            <div id="chat-window">
                <div id="result"></div>
                <div id="loading_div"></div>
                <!-- <div id="result_info"></div> -->
            </div>

            <label for="prompt">prompt:</label>
            <textarea id="prompt" rows="4" placeholder="What colour is the sky?"></textarea>



            <div id="input"></div>
            <button onclick="generateCompletion()">generate</button>


        </div>
    </div>


    <script>

        // document.getElementById('model').addEventListener('change', fetchModelInfo);
        document.getElementById('model').addEventListener('change', input_join);
        document.getElementById('prompt').addEventListener('change', input_join);
        document.getElementById('max_tokens').addEventListener('change', input_join);
        document.getElementById('temperature').addEventListener('change', input_join);
        document.getElementById('seed').addEventListener('change', input_join);
        document.getElementById('top_p').addEventListener('change', input_join);
        document.getElementById('top_k').addEventListener('change', input_join);
        document.getElementById('frequency_penalty').addEventListener('change', input_join);
        document.getElementById('presence_penalty').addEventListener('change', input_join);
        document.getElementById('repetition_penalty').addEventListener('change', input_join);






        async function fetchModelInfo() {
            const model = document.getElementById('model').value;
            const hfId = models_aliases[model]?.hfId;

            const resultDiv = document.getElementById('result_model_info');

            if (!model) {
                resultDiv.innerHTML = '';
                return;
            }

            resultDiv.innerHTML = 'Loading...';

            try {
                const response = await fetch(`https://huggingface.co/api/models?id=${hfId}`);
                console.log(model)
                console.log(hfId)
                const data = await response.json();

                if (!Array.isArray(data) || data.length === 0) {
                    resultDiv.innerHTML = 'No model info found.';
                    return;
                }

                const modelInfo = data[0];
                resultDiv.innerHTML = `<h3>Model Information</h3>
  <div class="field"><strong>Model Name:</strong> ${hfId}</div>
  <div class="field"><strong>Model ID:</strong> ${modelInfo.id}</div>
  <div class="field"><strong>Created At:</strong> ${new Date(modelInfo.createdAt).toLocaleString()}</div>
  <div class="field"><strong>Downloads:</strong> ${modelInfo.downloads.toLocaleString()}</div>
  <div class="field"><strong>Likes:</strong> ${modelInfo.likes.toLocaleString()}</div>
  <div class="field"><strong>Trending Score:</strong> ${modelInfo.trendingScore}</div>
  <div class="field"><strong>Tags:</strong> ${modelInfo.tags.join(', ')}</div>
  <div class="field"><strong>Library:</strong> ${modelInfo.library_name}</div>
  <div class="field"><strong>Pipeline:</strong> ${modelInfo.pipeline_tag}</div>
`;
            } catch (error) {
                console.error(error);
                resultDiv.innerHTML = 'Error fetching model info.';
            }
        }


        const inputDiv = document.getElementById('input');

        function input_join() {

            const prompt = document.getElementById("prompt").value.trim();
            const model = document.getElementById("model").value.trim();
            const max_tokens = document.getElementById("max_tokens").value.trim();
            const temperature = document.getElementById("temperature").value.trim();
            const seed = document.getElementById("seed").value.trim();
            const top_p = document.getElementById("top_p").value.trim();
            const top_k = document.getElementById("top_k").value.trim();
            const frequency_penalty = document.getElementById("frequency_penalty").value.trim();
            const presence_penalty = document.getElementById("presence_penalty").value.trim();
            const repetition_penalty = document.getElementById("repetition_penalty").value.trim();


            const input = {
                model: model,
                prompt: prompt
            }

            if (max_tokens) {
                input.reasoning = {};
                input.reasoning.max_tokens = Number(max_tokens);
            }
            if (temperature) {
                input.temperature = Number(temperature);
            }
            if (seed) {
                input.seed = Number(seed);
            }
            if (top_p) {
                input.top_p = Number(top_p);
            }
            if (top_k) {
                input.top_k = Number(top_k);
            }
            if (frequency_penalty) {
                input.frequency_penalty = Number(frequency_penalty);
            }
            if (presence_penalty) {
                input.presence_penalty = Number(presence_penalty);
            }
            if (repetition_penalty) {
                input.repetition_penalty = Number(repetition_penalty);
            }

            console.log(input)







            inputDiv.innerHTML = `<pre>${JSON.stringify(input, null, 4)}</pre>`;
            return input
        }




        async function generateCompletion() {
            const apiKey = document.getElementById("apiKey").value.trim();
           
            const model = document.getElementById("model").value;
            const prompt = document.getElementById("prompt").value;




            const resultDiv = document.getElementById("result");
            const resultInfo = document.getElementById("result_info");
            const loadingDiv = document.getElementById("loading_div");

            const input_send = input_join();
            console.log(input_send)

            const newInput = document.createElement('div');


            newInput.innerHTML = `<div class="msg"><h3 class="input">User Input</h3><pre>${JSON.stringify(input_send, null, 4)}</pre></div>`;
            resultDiv.appendChild(newInput);
            const chatWindow = document.getElementById('chat-window');
            chatWindow.scrollTop = chatWindow.scrollHeight;



            loadingDiv.innerHTML = `<p><br>Generating response...</p><img src="../assets/icons/spinner-ring.svg">`;
 if (!apiKey) {
                apikey = BETH_TEXT_KEY;
            }
            if (!prompt || !model) {
                resultDiv.innerHTML = "All fields are required.";

                return;
            }


            try {

                const response = await fetch(`https://openrouter.ai/api/v1/completions`, {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${apiKey}`,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify(input_send)

                });
                console.log(response);

                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.error || "Error generating response");

                }

                const result = await response.json();
                console.log(result);
                loadingDiv.innerHTML = "";



                const text_response = result.choices[0].text;
                const formattedText = text_response.replace(/\n\*\s+/g, '\n  â€¢ ').replace(/\n/g, '<br>').replace(/\*\*(.*?)\*\*/g, '<b>$1</b>').replace(/\*(.*?)\*/g, '<i>$1</i>');
                // const formattedText = text_response.replace('\n', '<br>');
                const finish_reason = result.choices[0].finish_reason;
                const response_id = result.id;


                const newResult = document.createElement('div.msg');
                newResult.innerHTML = `<div class="msg"><h3 class="output">${model}:</h3><p msg>${formattedText}<br><br>id: ${response_id}<br>finish_reason:${finish_reason}</p></div>`;
                resultDiv.appendChild(newResult);

                const chatWindow = document.getElementById('chat-window');
                chatWindow.scrollTop = chatWindow.scrollHeight;





                return result;
            } catch (error) {
                const newResult = document.createElement('div');
                newResult.innerHTML = `<p style="color: red;">Error: ${error.message}<br>Prompt: "${prompt}</p>"`;
                resultDiv.appendChild(newResult);

                const chatWindow = document.getElementById('chat-window');
                chatWindow.scrollTop = chatWindow.scrollHeight;
                console.error(error);

                // resultDiv.innerHTML = `<p style="color: red;">Error: ${error.message}</p><pre>${JSON.stringify(result, null, 4)}</pre>`;
            }
        }
    </script>

</body>

</html>
